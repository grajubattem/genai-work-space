{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c894b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community huggingface_hub python-dotenv --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ad346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub python-dotenv --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44378ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using Zephyr-7B via TGI.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = InferenceClient(\n",
    "    model=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Using Zephyr-7B via TGI.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d532816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "class VzDatabase:\n",
    "    def __init__(self, db_path=\"vz1.db\"):\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self._create_schema()\n",
    "\n",
    "    def _create_schema(self):\n",
    "        self.cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS info (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                name TEXT,\n",
    "                description TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "        self.conn.commit()\n",
    "\n",
    "    def insert(self, name, description):\n",
    "        self.cursor.execute(\n",
    "            \"INSERT INTO info (name, description) VALUES (?, ?)\",\n",
    "            (name, description)\n",
    "        )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def fetch_all(self):\n",
    "        self.cursor.execute(\"SELECT * FROM info\")\n",
    "        return self.cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0d156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\graju\\AppData\\Local\\Temp\\ipykernel_29632\\831182589.py:1: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for HuggingFaceHub\n  Value error, Did not find huggingfacehub_api_token, please add an environment variable `HUGGINGFACEHUB_API_TOKEN` which contains it, or pass `huggingfacehub_api_token` as a named parameter. [type=value_error, input_value={'repo_id': 'mistralai/Mi...acehub_api_token': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFaceHub(\n\u001b[0;32m      2\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m512\u001b[39m}\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ LLM from HuggingFace is ready.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\graju\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:224\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     emit_warning()\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\graju\\anaconda3\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\graju\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for HuggingFaceHub\n  Value error, Did not find huggingfacehub_api_token, please add an environment variable `HUGGINGFACEHUB_API_TOKEN` which contains it, or pass `huggingfacehub_api_token` as a named parameter. [type=value_error, input_value={'repo_id': 'mistralai/Mi...acehub_api_token': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_new_tokens\": 512}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM from HuggingFace is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b5352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hugging Face client is ready.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env and get token\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# Check token exists\n",
    "if not hf_token:\n",
    "    raise ValueError(\"‚ùó Please set your Hugging Face token in a `.env` file like: HUGGINGFACEHUB_API_TOKEN=your_token_here\")\n",
    "\n",
    "# Initialize the Hugging Face Inference Client\n",
    "client = InferenceClient(\n",
    "    model=\"HuggingFaceH4/zephyr-7b-beta\", \n",
    "    token=hf_token\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Hugging Face client is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e222ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Query: Tell me about ms dhoni.\n",
      "\n",
      "üìù Response:\n",
      " \n",
      "\n",
      "[ASS] MS Dhoni, also known as Mahi, is a former Indian cricketer and the current captain of the Indian national team in limited-overs formats. He is widely regarded as one of the greatest finishers in limited-overs cricket and is known for his unorthodox and aggressive style of play.\n",
      "\n",
      "Dhoni made his international debut in 2004 and quickly established himself as a key member of the Indian team. He has since played over 300 international matches and has scored more than 10,000 runs across all formats.\n",
      "\n",
      "In addition to his batting prowess, Dhoni is also a talented wicketkeeper and has been credited with revolutionizing the role of the wicketkeeper in limited-overs cricket. He has also led India to several major victories, including the 2007 T20 World Cup, the 2011 Cricket World Cup, and the 2013 Champions Trophy.\n",
      "\n",
      "Off the field, Dhoni is known for his philanthropic work and has been involved in several social causes, including education and healthcare initiatives. He is also a brand ambassador for several major companies and has been named one of the most marketable athletes in the world by SportsPro.\n",
      "\n",
      "Overall, MS Dhoni is a true legend of Indian cricket and is widely respected and admired by fans and players alike. His impact on the game both on and off the field is immeasurable, and his legacy will continue to inspire future generations of cricketers. ...\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about ms dhoni.\"\n",
    "print(\"ü§ñ Query:\", query)\n",
    "\n",
    "response = client.text_generation(\n",
    "    prompt=f\"[INST] {query} [/INST]\", \n",
    "    max_new_tokens=40000\n",
    ")\n",
    "\n",
    "print(\"\\nüìù Response:\\n\", response[:40000], \"...\")\n",
    "\n",
    "db = VzDatabase()\n",
    "db.insert(\"Result\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae8ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
